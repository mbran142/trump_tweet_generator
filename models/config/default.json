{
    "training": {
        "epochs": 8,
        "learning_rate": 1e-4,
        "patience": 4,
        "batch_size": 64
    },
    "model": {
        "hidden_size": 512,
        "embedding_size": 256,
        "num_layers": 3
    }
}